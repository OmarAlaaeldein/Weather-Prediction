{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import required libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get rid of null target column values and use them to test our model later"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "source": [
    "df=pd.read_csv(r\"weatherAUS.csv\")\r\n",
    "df.dropna(inplace=True,axis=0)\r\n",
    "\r\n",
    "labels=df[~((df.RainToday.isna())|(df.RainTomorrow.isna()))].RainTomorrow\r\n",
    "train=df[~((df.RainToday.isna())|(df.RainTomorrow.isna()))].drop([\"RainTomorrow\",\"Date\"],axis=1)\r\n",
    "print(train.Location.unique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Cobar' 'CoffsHarbour' 'Moree' 'NorfolkIsland' 'Sydney' 'SydneyAirport'\n",
      " 'WaggaWagga' 'Williamtown' 'Canberra' 'Sale' 'MelbourneAirport'\n",
      " 'Melbourne' 'Mildura' 'Portland' 'Watsonia' 'Brisbane' 'Cairns'\n",
      " 'Townsville' 'MountGambier' 'Nuriootpa' 'Woomera' 'PerthAirport' 'Perth'\n",
      " 'Hobart' 'AliceSprings' 'Darwin']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(train,labels,train_size=0.9)\r\n",
    "s = (X_train.dtypes == 'object')\r\n",
    "print(y_train.unique())\r\n",
    "object_cols = list(s[s].index)\r\n",
    "print(object_cols)\r\n",
    "d = (X_train.dtypes == 'float64')\r\n",
    "float_cols = list(d[d].index)\r\n",
    "print(float_cols)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Yes' 'No']\n",
      "['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
      "['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Impute\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(y_train.shape)\r\n",
    "my_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\r\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train[float_cols]))\r\n",
    "imputed_X_val = pd.DataFrame(my_imputer.transform(X_val[float_cols]))\r\n",
    "# Imputation removed column names; put them back\r\n",
    "print(X_train.shape)\r\n",
    "print(y_train.shape)\r\n",
    "imputed_X_train.columns= X_train[float_cols].columns\r\n",
    "imputed_X_val.columns = X_val[float_cols].columns\r\n",
    "\r\n",
    "# concat object_cols\r\n",
    "print(X_val.head)\r\n",
    "print(y_val.shape)\r\n",
    "X_train=X_train[object_cols].join(imputed_X_train)\r\n",
    "X_val=X_val[object_cols].join(imputed_X_val)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OneHot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "source": [
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\r\n",
    "\r\n",
    "# OneHot encode the training and val dataset categorical columns\r\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\r\n",
    "OH_cols_val = pd.DataFrame(OH_encoder.transform(X_val[object_cols]))\r\n",
    "# OneHot encode our 1D Target feratures\r\n",
    "final_y_train= pd.DataFrame(OH_encoder.fit_transform(pd.DataFrame(y_train)))\r\n",
    "final_y_val= pd.DataFrame(OH_encoder.transform(pd.DataFrame(y_val)))\r\n",
    "# Restore lost index series to to all data\r\n",
    "final_y_train.index=y_train.index\r\n",
    "final_y_val.index=y_val.index\r\n",
    "OH_cols_train.index=X_train.index\r\n",
    "OH_cols_val.index=X_val.index\r\n",
    "# Drop old categorical columns and concat with the OneHot encoded dataframe\r\n",
    "#print(X_train.head())\r\n",
    "X_train=X_train.drop(object_cols,axis=1)\r\n",
    "#print(X_train.head())\r\n",
    "X_val=X_val.drop(object_cols,axis=1)\r\n",
    "final_X_train=X_train.join(OH_cols_train)\r\n",
    "final_X_val=X_val.join(OH_cols_val)\r\n",
    "print(final_X_train.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "        MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "62176      12.9     15.4       0.4          1.2       0.0           26.0   \n",
      "130311      7.1     15.4       1.6          2.0       7.0           30.0   \n",
      "76697      11.5     16.9       0.2          6.6       3.6           52.0   \n",
      "23115      12.7     18.8       0.0          4.0       2.2           33.0   \n",
      "80338       9.0     14.9       0.0          1.8       3.8           22.0   \n",
      "\n",
      "        WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...   66   67  \\\n",
      "62176           13.0          13.0         92.0         91.0  ...  0.0  1.0   \n",
      "130311          13.0          15.0         64.0         64.0  ...  0.0  0.0   \n",
      "76697           28.0          31.0         78.0         75.0  ...  0.0  0.0   \n",
      "23115           17.0          15.0         87.0         82.0  ...  0.0  0.0   \n",
      "80338            9.0           7.0         93.0         58.0  ...  1.0  0.0   \n",
      "\n",
      "         68   69   70   71   72   73   74   75  \n",
      "62176   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "130311  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "76697   0.0  0.0  0.0  0.0  1.0  0.0  1.0  0.0  \n",
      "23115   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "80338   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "source": [
    "def score_dataset(n,X_train, X_valid, y_train, y_valid):\r\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=0)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    return accuracy_score(y_valid, preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "source": [
    "\r\n",
    "print(\"{} for {} estimators.\".format(score_dataset(j,final_X_train,final_X_val,final_y_train,final_y_val)*100,100))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "83edcf9d6691da80da87185edf1e2ec27aa1177a09f7d029aea1a0cb99dd36f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}