{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import required libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "import numpy as np\r\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get rid of null target column values and use them to test our model later"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "df=pd.read_csv(r\"weatherAUS.csv\")\r\n",
    "test=df[df.RainToday.isna()|df.RainTomorrow.isna()]\r\n",
    "labels=df[~((df.RainToday.isna())|(df.RainTomorrow.isna()))].RainTomorrow\r\n",
    "train=df[~((df.RainToday.isna())|(df.RainTomorrow.isna()))].drop([\"RainTomorrow\",\"Date\"],axis=1)\r\n",
    "print(train.Location.unique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Albury' 'BadgerysCreek' 'Cobar' 'CoffsHarbour' 'Moree' 'Newcastle'\n",
      " 'NorahHead' 'NorfolkIsland' 'Penrith' 'Richmond' 'Sydney' 'SydneyAirport'\n",
      " 'WaggaWagga' 'Williamtown' 'Wollongong' 'Canberra' 'Tuggeranong'\n",
      " 'MountGinini' 'Ballarat' 'Bendigo' 'Sale' 'MelbourneAirport' 'Melbourne'\n",
      " 'Mildura' 'Nhil' 'Portland' 'Watsonia' 'Dartmoor' 'Brisbane' 'Cairns'\n",
      " 'GoldCoast' 'Townsville' 'Adelaide' 'MountGambier' 'Nuriootpa' 'Woomera'\n",
      " 'Albany' 'Witchcliffe' 'PearceRAAF' 'PerthAirport' 'Perth' 'SalmonGums'\n",
      " 'Walpole' 'Hobart' 'Launceston' 'AliceSprings' 'Darwin' 'Katherine'\n",
      " 'Uluru']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "d = (train.dtypes == 'float64')\r\n",
    "float_cols = list(d[d].index)\r\n",
    "for i in float_cols:\r\n",
    "    print(i)\r\n",
    "    avg=train[i].mean()\r\n",
    "    train[i].fillna(value=avg,inplace=True)\r\n",
    "X_train,X_val,y_train,y_val=train_test_split(train,labels,train_size=0.95)\r\n",
    "s = (X_train.dtypes == 'object')\r\n",
    "object_cols = list(s[s].index)\r\n",
    "print(object_cols)\r\n",
    "\r\n",
    "print(X_train.isna().sum())\r\n",
    "print(X_val.isna().sum())\r\n",
    "print(y_val.isna().sum())\r\n",
    "print(y_train.isna().sum())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "MinTemp\n",
      "MaxTemp\n",
      "Rainfall\n",
      "Evaporation\n",
      "Sunshine\n",
      "WindGustSpeed\n",
      "WindSpeed9am\n",
      "WindSpeed3pm\n",
      "Humidity9am\n",
      "Humidity3pm\n",
      "Pressure9am\n",
      "Pressure3pm\n",
      "Cloud9am\n",
      "Cloud3pm\n",
      "Temp9am\n",
      "Temp3pm\n",
      "['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
      "Location            0\n",
      "MinTemp             0\n",
      "MaxTemp             0\n",
      "Rainfall            0\n",
      "Evaporation         0\n",
      "Sunshine            0\n",
      "WindGustDir      8729\n",
      "WindGustSpeed       0\n",
      "WindDir9am       9182\n",
      "WindDir3pm       3499\n",
      "WindSpeed9am        0\n",
      "WindSpeed3pm        0\n",
      "Humidity9am         0\n",
      "Humidity3pm         0\n",
      "Pressure9am         0\n",
      "Pressure3pm         0\n",
      "Cloud9am            0\n",
      "Cloud3pm            0\n",
      "Temp9am             0\n",
      "Temp3pm             0\n",
      "RainToday           0\n",
      "dtype: int64\n",
      "Location           0\n",
      "MinTemp            0\n",
      "MaxTemp            0\n",
      "Rainfall           0\n",
      "Evaporation        0\n",
      "Sunshine           0\n",
      "WindGustDir      434\n",
      "WindGustSpeed      0\n",
      "WindDir9am       478\n",
      "WindDir3pm       171\n",
      "WindSpeed9am       0\n",
      "WindSpeed3pm       0\n",
      "Humidity9am        0\n",
      "Humidity3pm        0\n",
      "Pressure9am        0\n",
      "Pressure3pm        0\n",
      "Cloud9am           0\n",
      "Cloud3pm           0\n",
      "Temp9am            0\n",
      "Temp3pm            0\n",
      "RainToday          0\n",
      "dtype: int64\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OneHot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\r\n",
    "\r\n",
    "# OneHot encode the training and val dataset categorical columns\r\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\r\n",
    "OH_cols_val = pd.DataFrame(OH_encoder.transform(X_val[object_cols]))\r\n",
    "# OneHot encode our 1D Target feratures\r\n",
    "final_y_train= pd.DataFrame(OH_encoder.fit_transform(pd.DataFrame(y_train)))\r\n",
    "final_y_val= pd.DataFrame(OH_encoder.transform(pd.DataFrame(y_val)))\r\n",
    "# Restore lost index series to to all data\r\n",
    "final_y_train.index=y_train.index\r\n",
    "final_y_val.index=y_val.index\r\n",
    "OH_cols_train.index=X_train.index\r\n",
    "OH_cols_val.index=X_val.index\r\n",
    "# Drop old categorical columns and concat with the OneHot encoded dataframe\r\n",
    "#print(X_train.head())\r\n",
    "X_train=X_train.drop(object_cols,axis=1)\r\n",
    "#print(X_train.head())\r\n",
    "X_val=X_val.drop(object_cols,axis=1)\r\n",
    "final_X_train=X_train.join(OH_cols_train)\r\n",
    "final_X_val=X_val.join(OH_cols_val)\r\n",
    "print(len(final_X_train))\r\n",
    "print(len(final_y_train))\r\n",
    "print(len(final_X_val))\r\n",
    "print(len(final_y_val))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "133747\n",
      "133747\n",
      "7040\n",
      "7040\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "def arg(l):\r\n",
    "    arr=[]\r\n",
    "    for i in l.values.tolist():\r\n",
    "        arr.append(np.argmax(i))\r\n",
    "    return np.array(arr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "def arg2(l):\r\n",
    "    arr=[]\r\n",
    "    for i in l:\r\n",
    "        arr.append(np.argmax(i))\r\n",
    "    return np.array(arr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "def score_dataset_RandomForest_OneHot(X_train, X_valid, y_train, y_valid,n):\r\n",
    "    model = RandomForestClassifier(n_estimators=n, random_state=0)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    return accuracy_score(y_valid, preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "def score_dataset_RandomForest(X_train, X_valid, y_train, y_valid,n):\r\n",
    "    model = RandomForestClassifier(n_estimators=n, random_state=0)\r\n",
    "    model.fit(X_train, arg(y_train))\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    return accuracy_score(arg(y_valid), arg2(preds))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def score_dataset_XGB(X_train, X_valid, y_train, y_valid,n):\r\n",
    "    model = XGBClassifier(n_estimators=n, random_state=0,use_label_encoder=False)\r\n",
    "    model.fit(X_train, arg(y_train))\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    print(len(preds))\r\n",
    "    return accuracy_score(arg(y_valid), arg2(preds))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "def score_dataset_GradientBoosting(X_train, X_valid, y_train, y_valid,n):\r\n",
    "    model = GradientBoostingClassifier(n_estimators=n, random_state=0)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    return accuracy_score(y_valid, preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "n=200\r\n",
    "print(\"{}% for {} estimators.\".format(score_dataset_RandomForest_OneHot(final_X_train,final_X_val,final_y_train,final_y_val,n)*100,n))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "85.68181818181819% for 200 estimators.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit (conda)"
  },
  "interpreter": {
   "hash": "83edcf9d6691da80da87185edf1e2ec27aa1177a09f7d029aea1a0cb99dd36f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}