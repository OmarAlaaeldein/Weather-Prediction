{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Import required libraries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "source": [
    "import pandas as pd\r\n",
    "from sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "from sklearn.impute import SimpleImputer\r\n",
    "from sklearn.metrics import accuracy_score\r\n",
    "import numpy as np\r\n",
    "from xgboost import XGBClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Get rid of null target column values and use them to test our model later"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "source": [
    "df=pd.read_csv(r\"weatherAUS.csv\")\r\n",
    "df.dropna(inplace=True,axis=0)\r\n",
    "\r\n",
    "labels=df[~((df.RainToday.isna())|(df.RainTomorrow.isna()))].RainTomorrow\r\n",
    "train=df[~((df.RainToday.isna())|(df.RainTomorrow.isna()))].drop([\"RainTomorrow\",\"Date\"],axis=1)\r\n",
    "print(train.Location.unique())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Cobar' 'CoffsHarbour' 'Moree' 'NorfolkIsland' 'Sydney' 'SydneyAirport'\n",
      " 'WaggaWagga' 'Williamtown' 'Canberra' 'Sale' 'MelbourneAirport'\n",
      " 'Melbourne' 'Mildura' 'Portland' 'Watsonia' 'Brisbane' 'Cairns'\n",
      " 'Townsville' 'MountGambier' 'Nuriootpa' 'Woomera' 'PerthAirport' 'Perth'\n",
      " 'Hobart' 'AliceSprings' 'Darwin']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "source": [
    "X_train,X_val,y_train,y_val=train_test_split(train,labels,train_size=0.9)\r\n",
    "s = (X_train.dtypes == 'object')\r\n",
    "print(y_train.unique())\r\n",
    "object_cols = list(s[s].index)\r\n",
    "print(object_cols)\r\n",
    "d = (X_train.dtypes == 'float64')\r\n",
    "float_cols = list(d[d].index)\r\n",
    "print(float_cols)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Yes' 'No']\n",
      "['Location', 'WindGustDir', 'WindDir9am', 'WindDir3pm', 'RainToday']\n",
      "['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Impute\r\n",
    "\r\n",
    "print(X_train.shape)\r\n",
    "print(y_train.shape)\r\n",
    "my_imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\r\n",
    "imputed_X_train = pd.DataFrame(my_imputer.fit_transform(X_train[float_cols]))\r\n",
    "imputed_X_val = pd.DataFrame(my_imputer.transform(X_val[float_cols]))\r\n",
    "# Imputation removed column names; put them back\r\n",
    "print(X_train.shape)\r\n",
    "print(y_train.shape)\r\n",
    "imputed_X_train.columns= X_train[float_cols].columns\r\n",
    "imputed_X_val.columns = X_val[float_cols].columns\r\n",
    "\r\n",
    "# concat object_cols\r\n",
    "print(X_val.head)\r\n",
    "print(y_val.shape)\r\n",
    "X_train=X_train[object_cols].join(imputed_X_train)\r\n",
    "X_val=X_val[object_cols].join(imputed_X_val)\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# OneHot"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "source": [
    "OH_encoder = OneHotEncoder(handle_unknown='ignore', sparse=False)\r\n",
    "\r\n",
    "# OneHot encode the training and val dataset categorical columns\r\n",
    "OH_cols_train = pd.DataFrame(OH_encoder.fit_transform(X_train[object_cols]))\r\n",
    "OH_cols_val = pd.DataFrame(OH_encoder.transform(X_val[object_cols]))\r\n",
    "# OneHot encode our 1D Target feratures\r\n",
    "final_y_train= pd.DataFrame(OH_encoder.fit_transform(pd.DataFrame(y_train)))\r\n",
    "final_y_val= pd.DataFrame(OH_encoder.transform(pd.DataFrame(y_val)))\r\n",
    "# Restore lost index series to to all data\r\n",
    "final_y_train.index=y_train.index\r\n",
    "final_y_val.index=y_val.index\r\n",
    "OH_cols_train.index=X_train.index\r\n",
    "OH_cols_val.index=X_val.index\r\n",
    "# Drop old categorical columns and concat with the OneHot encoded dataframe\r\n",
    "#print(X_train.head())\r\n",
    "X_train=X_train.drop(object_cols,axis=1)\r\n",
    "#print(X_train.head())\r\n",
    "X_val=X_val.drop(object_cols,axis=1)\r\n",
    "final_X_train=X_train.join(OH_cols_train)\r\n",
    "final_X_val=X_val.join(OH_cols_val)\r\n",
    "print(final_X_train.head())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "       MinTemp  MaxTemp  Rainfall  Evaporation  Sunshine  WindGustSpeed  \\\n",
      "76890      8.5     11.9       6.8          2.0       0.9           74.0   \n",
      "65966     14.2     42.2       0.0         12.6      12.5           44.0   \n",
      "72629      6.7     17.6       0.0          2.4      10.2           30.0   \n",
      "39820      9.8     18.6      20.0          3.4       6.4           33.0   \n",
      "75477      7.7     13.2       1.8          1.0       2.6           19.0   \n",
      "\n",
      "       WindSpeed9am  WindSpeed3pm  Humidity9am  Humidity3pm  ...   66   67  \\\n",
      "76890          24.0          44.0         94.0         76.0  ...  0.0  0.0   \n",
      "65966           7.0          26.0         76.0          7.0  ...  0.0  0.0   \n",
      "72629          11.0          13.0         87.0         51.0  ...  1.0  0.0   \n",
      "39820          11.0          26.0         86.0         74.0  ...  0.0  0.0   \n",
      "75477           7.0           4.0         99.0         94.0  ...  1.0  0.0   \n",
      "\n",
      "        68   69   70   71   72   73   74   75  \n",
      "76890  0.0  0.0  0.0  0.0  0.0  1.0  0.0  1.0  \n",
      "65966  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "72629  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
      "39820  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "75477  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  \n",
      "\n",
      "[5 rows x 92 columns]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "source": [
    "def arg(l):\r\n",
    "    arr=[]\r\n",
    "    for i in l.values.tolist():\r\n",
    "        arr.append(np.argmax(i))\r\n",
    "    return np.array(arr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "source": [
    "def arg2(l):\r\n",
    "    arr=[]\r\n",
    "    for i in l:\r\n",
    "        arr.append(np.argmax(i))\r\n",
    "    return np.array(arr)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "source": [
    "def score_dataset_RandomForest_OneHot(X_train, X_valid, y_train, y_valid):\r\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=0)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    return accuracy_score(y_valid, preds)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "source": [
    "def score_dataset_RandomForest(X_train, X_valid, y_train, y_valid):\r\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=0)\r\n",
    "    model.fit(X_train, arg(y_train))\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    return accuracy_score(arg(y_valid), arg2(preds))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "source": [
    "def score_dataset_XGB(X_train, X_valid, y_train, y_valid):\r\n",
    "    model = XGBClassifier(n_estimators=100, random_state=0,use_label_encoder=False)\r\n",
    "    model.fit(X_train, arg(y_train))\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    return accuracy_score(arg(y_valid), arg2(preds))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "def score_dataset(X_train, X_valid, y_train, y_valid):\r\n",
    "    model = GradientBoostingClassifier(n_estimators=100, random_state=0)\r\n",
    "    model.fit(X_train, y_train)\r\n",
    "    preds = model.predict(X_valid)\r\n",
    "    return accuracy_score(y_valid, preds)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "source": [
    "\r\n",
    "print(\"{} for {} estimators.\".format(score_dataset_RandomForest_OneHot(final_X_train,final_X_val,final_y_train,final_y_val)*100,100))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "85.8560794044665 for 100 estimators.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.8",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit"
  },
  "interpreter": {
   "hash": "83edcf9d6691da80da87185edf1e2ec27aa1177a09f7d029aea1a0cb99dd36f7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}